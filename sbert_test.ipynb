{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, losses\n",
    "from sentence_transformers.readers import STSDataReader\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers.InputExample import InputExample\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase swap size:\n",
    "# https://superuser.com/questions/1024064/change-swap-file-size-fedora-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wiki = SentenceTransformer('bert-base-wikipedia-sections-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.get_max_seq_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['A fox lives in a zoo together with dogs.',\n",
    "            'Sentences are passed as a list of string.', \n",
    "            'The quick brown fox jumps over the lazy dog.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01991861, 0.01082202])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model_wiki.encode(sentences)\n",
    "sims = cdist(embeddings[0].reshape(-1,1).T, embeddings[1:], \"cosine\")[0]\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95112492, 0.58440415])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model_1.encode(sentences)\n",
    "sims = cdist(embeddings[0].reshape(-1,1).T, embeddings[1:], \"cosine\")[0]\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataReader(STSDataReader):\n",
    "    '''\n",
    "    Need to reimplement get_examples method from class STSDataReader because\n",
    "    our csv file has a header.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, dataset_folder, **kwargs):\n",
    "        super(MyDataReader,self).__init__(dataset_folder, **kwargs)\n",
    "        \n",
    "    def get_examples(self, filename, header=True, max_examples=0):\n",
    "        \"\"\"\n",
    "        filename specified which data split to use (train.csv, dev.csv, test.csv).\n",
    "        \"\"\"erläutern\n",
    "        data = csv.reader(open(os.path.join(self.dataset_folder, filename), encoding=\"utf-8\"),\n",
    "                          delimiter=self.delimiter, quoting=self.quoting)\n",
    "        if header:\n",
    "            next(data, None)  # skip the header\n",
    "        examples = []\n",
    "        for id, row in enumerate(data):\n",
    "            score = float(row[self.score_col_idx])\n",
    "            if self.normalize_scores:  # Normalize to a 0...1 value\n",
    "                score = (score - self.min_score) / (self.max_score - self.min_score)\n",
    "\n",
    "            s1 = row[self.s1_col_idx]\n",
    "            s2 = row[self.s2_col_idx]\n",
    "            examples.append(InputExample(guid=filename+str(id), texts=[s1, s2], label=score))\n",
    "\n",
    "            if max_examples > 0 and len(examples) >= max_examples:\n",
    "                break\n",
    "\n",
    "        return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<sentence_transformers.readers.InputExample.InputExample at 0x7f382bd049e8>,\n",
       " <sentence_transformers.readers.InputExample.InputExample at 0x7f382bd04a58>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myreader = MyDataReader('/run/media/root/Windows/Users/agnes/Downloads/data/msmarco/',\n",
    "                       s1_col_idx=1,\n",
    "                       s2_col_idx=4,\n",
    "                       score_col_idx=2,\n",
    "                       delimiter=\",\",\n",
    "                       quoting=csv.QUOTE_MINIMAL,\n",
    "                       normalize_scores=False, min_score=0, max_score=1)\n",
    "\n",
    "myreader.get_examples('queries_od.csv', max_examples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert dataset: 100%|██████████| 100/100 [00:00<00:00, 462.88it/s]\n"
     ]
    }
   ],
   "source": [
    "my_data = SentencesDataset(examples=myreader.get_examples(\"queries_od.csv\", max_examples=100), \n",
    "                           model=model_1,\n",
    "                          show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_l = SentenceLabelDataset(examples=myreader.get_examples(\"queries_od.csv\", max_examples=100), \n",
    "                           model=model_wiki,\n",
    "                          show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "train_batch_size = 8\n",
    "\n",
    "warmup_steps = math.ceil(len(my_data)*num_epochs/train_batch_size*0.1) #10% of train data for warm-up\n",
    "\n",
    "optimizer_class = transformers.AdamW\n",
    "optimizer_params = {'lr': 2e-5, 'eps': 1e-6, 'correct_bias': False}\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model=model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = DataLoader(my_data, shuffle=False, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/run/media/root/Windows/Users/agnes/Downloads/data/msmarco/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output_path = os.path.join(MODEL_DIR, 'test_model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 1/13 [00:13<02:39, 13.28s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 2/13 [00:56<02:42, 14.77s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 3/13 [01:39<02:41, 16.17s/it]\u001b[A\n",
      "Iteration:  31%|███       | 4/13 [01:59<02:27, 16.37s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 5/13 [02:20<02:12, 16.59s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 6/13 [02:39<01:57, 16.73s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 7/13 [02:55<01:40, 16.68s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 8/13 [03:14<01:24, 16.84s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 9/13 [03:35<01:08, 17.00s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 10/13 [03:55<00:51, 17.16s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 11/13 [04:11<00:34, 17.11s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 12/13 [04:31<00:17, 17.25s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 13/13 [04:43<00:00, 21.81s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 1/1 [04:43<00:00, 283.55s/it]\n"
     ]
    }
   ],
   "source": [
    "model_1.fit(train_objectives=[(my_dataloader, train_loss)],\n",
    "          evaluator=None,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          optimizer_class=optimizer_class,\n",
    "          optimizer_params=optimizer_params,\n",
    "          output_path=my_output_path) # works only when you have an evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(my_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# model_1 = SentenceTransformer(my_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27484048, 0.14570002])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model_1.encode(sentences)\n",
    "sims = cdist(embeddings[0].reshape(-1,1).T, embeddings[1:], \"cosine\")[0]\n",
    "sims"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity-project",
   "language": "python",
   "name": "udacity-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
