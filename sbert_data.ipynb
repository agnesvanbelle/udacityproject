{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import transformers\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, losses\n",
    "from sentence_transformers.readers import STSDataReader, TripletReader\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, BinaryEmbeddingSimilarityEvaluator, SequentialEvaluator\n",
    "from sentence_transformers.readers.InputExample import InputExample\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SPLITS_DATA_DIR = 'msmarco/train_data/splitted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# increase swap size:\n",
    "# https://superuser.com/questions/1024064/change-swap-file-size-fedora-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_wiki = SentenceTransformer('bert-base-wikipedia-sections-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_1 = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.get_max_seq_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = ['A fox lives in a zoo together with dogs.',\n",
    "            'Sentences are passed as a list of string.', \n",
    "            'The quick brown fox jumps over the lazy dog.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = model_wiki.encode(sentences)\n",
    "sims = cdist(embeddings[0].reshape(-1,1).T, embeddings[1:], \"cosine\")[0]\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95112494, 0.58440401])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model_1.encode(sentences)\n",
    "sims = cdist(embeddings[0].reshape(-1,1).T, embeddings[1:], \"cosine\")[0]\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datareader for the regression/raw data\n",
    "class MyDataReader(STSDataReader):\n",
    "    '''\n",
    "    Need to reimplement get_examples method from class STSDataReader because\n",
    "    our csv file has a header.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, dataset_folder, **kwargs):\n",
    "        super(MyDataReader,self).__init__(dataset_folder, **kwargs)\n",
    "        \n",
    "    def get_examples(self, filename, header=True, max_examples=0):\n",
    "        \"\"\"\n",
    "        filename specified which data split to use (train.csv, dev.csv, test.csv).\n",
    "        \"\"\"\n",
    "        data = csv.reader(open(os.path.join(self.dataset_folder, filename), encoding=\"utf-8\"),\n",
    "                          delimiter=self.delimiter, quoting=self.quoting)\n",
    "        if header:\n",
    "            next(data, None)  # skip the header\n",
    "        examples = []\n",
    "        for id, row in enumerate(data):\n",
    "            score = float(row[self.score_col_idx])\n",
    "            if self.normalize_scores:  # Normalize to a 0...1 value\n",
    "                score = (score - self.min_score) / (self.max_score - self.min_score)\n",
    "\n",
    "            s1 = row[self.s1_col_idx]\n",
    "            s2 = row[self.s2_col_idx]\n",
    "            examples.append(InputExample(guid=filename+str(id), texts=[s1, s2], label=score))\n",
    "\n",
    "            if max_examples > 0 and len(examples) >= max_examples:\n",
    "                break\n",
    "\n",
    "        return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_data_path = os.path.join(TRAIN_SPLITS_DATA_DIR, 'queries3_sentences_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<sentence_transformers.readers.InputExample.InputExample at 0x7fa22f44f4e0>,\n",
       " <sentence_transformers.readers.InputExample.InputExample at 0x7fa22f44f2e8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myreader_regression = MyDataReader(\n",
    "                       my_train_data_path,\n",
    "                       s1_col_idx=1,\n",
    "                       s2_col_idx=3,\n",
    "                       score_col_idx=2,\n",
    "                       delimiter=\",\",\n",
    "                       quoting=csv.QUOTE_MINIMAL,\n",
    "                       normalize_scores=False, min_score=0, max_score=1)\n",
    "\n",
    "myreader_regression.get_examples('queries3_sentences_regression_dev.csv', max_examples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert dataset: 100%|██████████| 100000/100000 [00:40<00:00, 2496.65it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = myreader_regression.get_examples('queries3_sentences_regression_train.csv', max_examples=100000)\n",
    "train_dataset = SentencesDataset(train_data, show_progress_bar=True, model=model_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert dataset: 100%|██████████| 16259/16259 [00:06<00:00, 2588.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = SentencesDataset(\n",
    "    myreader_regression.get_examples('queries3_sentences_regression_dev.csv', max_examples=20000), \n",
    "    show_progress_bar=True, model=model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset_sampler = RandomSampler(dev_dataset, replacement=True, num_samples=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_sampler = RandomSampler(train_dataset, replacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataloader = DataLoader(dev_dataset, batch_size=train_batch_size)#, sampler=dev_dataset_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size, num_workers=1)#, sampler=train_dataset_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16259"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_path = 'msmarco/models/test_model5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dev_dataloader, os.path.join(my_model_path, 'dev_dataloader.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataloader, os.path.join(my_model_path, 'train_dataloader.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
